---
title: "Youtube Video"
author: Chuyue Xie
output: 
    html_notebook:
    fig_height: 6
    fig_width: 12
---
# Motivation
YouTube has become one of the most popular worldwide video sharing platform nowadays. It includes videos varying from music videos to makeup tutorials, from lifestyle vlog to education videos... YouTube seem be be a hub of creativity and informations. The main purpose of this project is to explore the following questions:
1. What is the most popular comment for the top trending videos in the United States?
2. Is there any difference in people's favor in terms of video types among the United States and South Korea?

# Data Source
For this project, the dataset used is found at Kaggle published by Mitchell J, a software developer at Backbeat Technologies. The version this project based on is version 115. The following is a weblink to the Kaggle page of the dataset: [Trending YouTube Video Statistics](https://www.kaggle.com/datasnaek/youtube-new). The main dataset used in this project are *USvideos.csv*. Other supporting datasets are *KRvideos.csv*, *US_category_id.json*, *KR_category_id.json*, and 

# Set Up

### Clean up environment and load packages
```{r message=FALSE, paged.print=FALSE}
# clean up the RStudio environment 
rm(list = ls())

# load all packages here: `mosaic`, `tidyverse`, `lubridate`, and all others used
library(mosaic)
library(tidyverse)
library(lubridate)
library(DataComputing)
library(ggplot2)
library(rjson)
library(rvest)
library(party)
```

### Data Intake
The codes below read in data tables from csv files.
```{r message=FALSE, warning=FALSE}
### Load US videos data from USvideos.csv
US_data <- read_csv("USvideos.csv") #full data with 40949 rows
#US_sub_data <- # small data with 10k rows
  #US_data %>%
  #head(10000)
US_category_table <- fromJSON(file = "US_category_id.json") #table of category value for US
```

### Data Table Inspection
To start with, the main table with video information for US and its category names is shown below:
```{r message=FALSE, include=FALSE, paged.print=FALSE}
### US videos dataset
US_data %>%
  glimpse() #the glimpse function will present the columns down the page and rows across

### US category datatable
print("US category datatable")
US_category_table %>%
  glimpse()
```
According to the output, there are 16 variables in total for US video datasets. This includes video id, trending date (chr), title (chr), channel title (chr), category id (dbl), publish time (dttm), tags (chr), views (dbl), likes (dbl), dislikes (dbl), comment count (dbl), thumbnail link (chr), comments disabled (lgl), ratings disabled (lgl), and video error or removed (lgl), and description (chr). 

Moreover, for the category dataset, it they look a little messy. There are a 32 levels for US category datasets. Further cleaning of the data table will be conducted in later steps.

In order to decrease the dimension of the tables and prepare it for further analysis, the next step is to transform variable type and clean the data table.

### Data Preprocessing

In this project, the main focus will be place on variables including video id, trending date, channel title, category id, publish time, views, liks, dislikes, and description for US data. For the South Korea videos data, only video id, trending date, category id, publish time, views, and descriptions will be used in this project. Other variables will be revoved.

```{r}
### Select variables for the US dataset
US_data <-
  US_data %>%
  select(video_id, trending_date, title, channel_title, category_id, category_id, publish_time, views, likes, dislikes, description) 
```

Notice that trending date and category id are not in the right form. Trending date should be a time variable, but is recognized as a character string. Moreover, category id should be a character string, but is recognized as a number. In the next step, variables trending date and category id are converted into the correct format.

```{r}
### Convert variables for the US video dataset
US_data <-
  US_data %>%
  mutate(trending_date = ydm(trending_date), category_id = as.character(category_id))
```

For the original dataset, the category id variable is named as numbers. In order to give it more meanings, it is transformed into real video category names for furhter analysis.

```{r}
#Step 1: Use the US category table fo create a table for category id&name conversion
id <- rep(c(0), 32) #ccreate a string with length 32 with values equal to 0
name <- rep(c(0), 32) #create a string with length 32 with values equal to 0

### Use US category table to define id and their corresponding movie category name
for (i in 1:32){
  id[i] = US_category_table$items[[i]]$id
  name[i] = US_category_table$items[[i]]$snippet$title
}

### Create a new table that contain the name of each category id
category_name_US <- 
  list(category_id = id, category_name = name) %>%
  as.data.frame()

# Step 2: Join the US video table with the category name table.
### US videos data
US_data <-
  US_data %>%
  left_join(category_name_US)
```

The following will show the first few rows of the data to demonstrate the data used in further sections.
```{r}
### US videos data
US_data %>%
  head()
```

# Section: Most popular trending video category across time in the US and South Korea
In this section, the most popular video category among time in the United States and South Korea is compared. 

### Step 1: Overview of US video categories
```{r warning=FALSE}
### Most Popular Categories for US
US_data %>%
#  group_by(category_name) %>%
#  summarise(count = n())%>%
#  arrange(desc(count)) #%>%
#  mutate(category_name = as.character(category_name), category_name = ifelse(count > 3000, category_name, "Others")) %>%
  ggplot(aes(x = category_name, fill = category_name)) +
  geom_bar(stat = "count") +
  xlim(c("Entertainment", "Music", "Howto & Style", "Comedy", "People & Blogs", "News & Politics", "Science & Technology", "Film & Animation", "Sports", "Education"))+ theme(axis.text.x = element_text(angle = 90, hjust = 1))
 # coord_polar("y", start = 0)
```



# Section: Monthly Trending "Title Phrase"

YouTubers always want to get most viewers' attention by making effort in the video titles. In the following analysis, the main purpose is to understand which are the most commonly used phrases among trending YouTube videos. More importantly, how does the use of vocabulary change over time. This analysis will be based on the US dataset.

In order to analysis the montly trend, the dataset will need to be splitted into monthly pieces. Moreover, the title string should be splitted into individual words, which adds up to counts for each vocabulary. The following steps demonstrate this process.

### Step 1: Word Count Function

In order to count the word-use frequency, the following function is constructed below to help with separating the title into vocabularies, removing punctuations, and count the amount of word altogether.

```{r}
word_count <- function(variable){
  variable <- gsub('[[:punct:] ]+',' ',variable) ### remove punctuation
  list <- c() ### empty vector
  num <- c() ### empty vector
  for (i in 1:length(variable)){
    string <- variable[i]
    #print(string)
    words <- tolower(unlist(strsplit(string, " "))) ###split the title string
    #print(words)
    for (j in 1:length(words)){
      #print(j)
      position <- match(words[j], list) ###define the position of the vocab in list
      list_length <- length(list) ###calculate the length of list
      num_len <- length(num) ### calculate the length of number
      if (is.na(position) == FALSE){ ### if item in the list
        num[position] <- num[position]+1 ### add a count to the vocab
      }
      else{ ### ekse if vocab not in the list
        list[list_length+1] = words[j] ###create a new row in list
        num[num_len+1] = 1 ### setnumber of elements to 1 for that vocab
      }
    }
  }
  df <- data.frame(list = list, num = num) ### create a dataframe that combine the list of vocab and their count
  return(df)
}
```

### Step 2: Monthly Data Preprocessing
In this step, the entire US dataset is splitted into 8 pieces from November to June
```{r}
Nov <- US_data %>%
  mutate(trending_date = month(trending_date)) %>%
  filter(trending_date == 11)
Dec <- US_data %>%
  mutate(trending_date = month(trending_date)) %>%
  filter(trending_date == 12)
Jan <- US_data %>%
  mutate(trending_date = month(trending_date)) %>%
  filter(trending_date == 1)
Feb <- US_data %>%
  mutate(trending_date = month(trending_date)) %>%
  filter(trending_date == 2)
Mar <- US_data %>%
  mutate(trending_date = month(trending_date)) %>%
  filter(trending_date == 3)
April <- US_data %>%
  mutate(trending_date = month(trending_date)) %>%
  filter(trending_date == 4)
May <- US_data %>%
  mutate(trending_date = month(trending_date)) %>%
  filter(trending_date == 5)
June <- US_data %>%
  mutate(trending_date = month(trending_date)) %>%
  filter(trending_date == 6)
```

### Step 3: Word Count for Each Month
Then, the vocab function is applied to each month's data. The result will be the trending vocab in video titles.
```{r}
Nov_title <- as.vector(Nov$title)
Nov_vocab <- word_count(Nov_title) %>%
  arrange(desc(num)) %>%
  mutate(month = "Nov")

Dec_title <- as.vector(Dec$title)
Dec_vocab <- word_count(Dec_title) %>%
  arrange(desc(num)) %>%
  mutate(month = "Dec")

Jan_title <- as.vector(Jan$title)
Jan_vocab <- word_count(Jan_title) %>%
  arrange(desc(num))%>%
  mutate(month = "Jan")

Feb_title <- as.vector(Feb$title)
Feb_vocab <- word_count(Feb_title) %>%
  arrange(desc(num))%>%
  mutate(month = "Feb")

Mar_title <- as.vector(Mar$title)
Mar_vocab <- word_count(Mar_title) %>%
  arrange(desc(num))%>%
  mutate(month = "Mar")

April_title <- as.vector(April$title)
April_vocab <- word_count(April_title) %>%
  arrange(desc(num))%>%
  mutate(month = "April")

May_title <- as.vector(May$title)
May_vocab <- word_count(May_title) %>%
  arrange(desc(num))%>%
  mutate(month = "May")

June_title <- as.vector(June$title)
June_vocab <- word_count(June_title) %>%
  arrange(desc(num))%>%
  mutate(month = "June")
```
These tables are binded together for further analysis.
```{r}
Vocab_Count <-
  rbind(Nov_vocab, Dec_vocab, Jan_vocab, Feb_vocab, Mar_vocab, April_vocab, May_vocab, June_vocab)
Vocab_Count
```
According to the table, words that do not have much meaning seem to show on top of the list, including "the", "s", "a"...

### Table Cleanup and Visualization
Since some of the words in the table above do not provide any meaningful insights, they are removed in this step.

```{r}
### List of STOP words (popular preposition and pronouns that have no actual meaning)
prep_n_pron <- "^(the|a|s|at|to|of|with|in|on|and|i|you|for|is|am|are|my|it|ft|from|your|this|the|up|by|his|off|official|video|2|day|year|we|me|t|how|what|first)$"
Vocab_Count <- 
  Vocab_Count %>% 
  filter(!grepl(prep_n_pron, list))
Vocab_Count
```



### Step 5: Monthly Visualization

Next, a plot showing how top 5 popular vocabularies of each month change from November 2018 to June 2019 is plotted.

```{r}


### remove these from the list of popular words
Vocab_Count %>%
  group_by(month) %>%
  top_n(4, num) %>%
  ggplot(aes(x = month, y = num))+
  #geom_point(aes(color = list), size = 2, alpha = 0.5)+
  geom_text(aes(label=list, color = list), angle = 45, alpha = 0.8, nudge_y =1) +
  xlim(c("Nov", "Dec", "Jan", "Feb", "Mar", "April", "May", "June"))+
  ylab("count")

```

According to the plot, the most popular words used in the videos overall is year number. Words such as 2017 and 2018 are used more often by the end of and at the beggining of each year. By the end of 2017, music, trailer, and stars seem to become the most common topic among videos. Moreover, in December, wehn Chirstmas is about to come, the word "Christmas" also become very common in video titles. In the beginning of 2018, the word "new" was used commonly, which may due to the new year just begins. Then, in Feburary, when is the super bowl season, the words super and bowl often appear in the titles. It is also very interesting that more makeup videos became trending in spring 2018. 

